{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "luA6ukkovBY4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip\n",
        "!pip install tensorflow numpy==1.16 sklearn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "65gUmF3xvBY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf606c78-8b0c-47a3-bb52-b04116fd318b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MTdG8yK4vBY8"
      },
      "outputs": [],
      "source": [
        "corpus_raw = 'He is the king . The king is royal . She is the royal queen '\n",
        "corpus_raw = corpus_raw.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xufh3-UCvBY9"
      },
      "outputs": [],
      "source": [
        "\n",
        "words = []\n",
        "words = corpus_raw.split()\n",
        "# parse through the corpus and remove the dots\n",
        "words = [word.strip('ã€‚') for word in words]\n",
        "\n",
        "\n",
        "# Convert words into integers and vice versa\n",
        "word2int = {}\n",
        "int2word = {}\n",
        "vocab_size = len(words)\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "    # TODO 1: Fill in the logic for word2int and int2word mappings\n",
        "    # for example: word_to_int has words as keys and integers as value\n",
        "     if word not in word2int:\n",
        "        # Assign a unique integer to each word\n",
        "        word2int[word] = i\n",
        "        int2word[i] = word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eZTAULahvBY9"
      },
      "outputs": [],
      "source": [
        "# raw sentences is a list of sentences.\n",
        "raw_sentences = corpus_raw.split('.')\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "    sentences.append(sentence.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XY4PX568vBY9"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 2\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for word_index, word in enumerate(sentence):\n",
        "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] :\n",
        "            if nb_word != word:\n",
        "                data.append([word, nb_word])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NS7EQu0vBY-"
      },
      "source": [
        "### ***What does the previous cell do ?***\n",
        "* ***Your** thoughts here*\n",
        "This code block processes the raw text data, labels it as sentences and words, and then creates word pairs where one word is the target word and the other is the context word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V9zXWazcvBY_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def to_one_hot(data_point_index, vocab_size):\n",
        "    # TODO 2: Implement the one-hot encoding function here.\n",
        "    # initialize a list of zeros equal to vocab_size\n",
        "    # turn this list into a one hot vector for the data_point_index\n",
        "    one_hot_vector = [0] * vocab_size\n",
        "    one_hot_vector[data_point_index] = 1\n",
        "\n",
        "    return one_hot_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "crpHCBdSvBY_"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train = [] # input words\n",
        "y_train = [] # output words\n",
        "\n",
        "for data_word in data:\n",
        "    # TODO 3: Append appropriate one-hot encoded vectors to x_train and y_train\n",
        "    target_word, context_word = data_word[0], data_word[1]\n",
        "    x_train.append(to_one_hot(word2int[context_word], vocab_size))\n",
        "    y_train.append(to_one_hot(word2int[target_word], vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RQ0L9KpgvBZA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert lists to numpy arrays\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fs6YmH4vBZA"
      },
      "source": [
        "### ***What does the previous cell do ?***\n",
        "* ***Your** thoughts here*\n",
        "This code prepares training data by converting word pairs into solo thermal encoding vectors, making it suitable for training a word-skipping word embedding model. The model learns to predict context words from the target word and is typically used to generate word embeddings that capture semantic relationships between words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qljhdfwgvBZA"
      },
      "outputs": [],
      "source": [
        "\n",
        "EMBEDDING_DIM = 5\n",
        "\n",
        "# TODO 5: Initialize weight matrices W1 and W2 with random values, and biases b1 and b2.\n",
        "# Use tf.Variable and tf.random_normal with the appropriate shapes to initialize layers and biases\n",
        "# look at the slides if you don't remember the layer shapes\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM], stddev=0.01))\n",
        "b1 = tf.Variable(tf.zeros([EMBEDDING_DIM]))\n",
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size], stddev=0.01))\n",
        "b2 = tf.Variable(tf.zeros([vocab_size]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e6ROdkRZvBZB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO 6: Calculate the hidden representation of the word.\n",
        "# \"hidden representation\" means the value of the vector after the first layer\n",
        "# i.e. the vector within the latent space of the network\n",
        "# use tf.add and tf.matmul\n",
        "\n",
        "hidden_representation = tf.add(tf.matmul(x, W1), b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ay6mXqNivBZB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO 7: Compute the prediction, the output from the output layer.\n",
        "# hint: the prediction follows is the hidden representation passed through the second layer\n",
        "# don't forget to add the softmax to turn the outputs into a probability distribution\n",
        "# you may use tf.nn.softmax for that\n",
        "output_layer_input = tf.add(tf.matmul(hidden_representation, W2), b2)\n",
        "prediction = tf.nn.softmax(output_layer_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dt51ptaCvBZB"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_3V3vrxvBZB"
      },
      "source": [
        "### ***What does the previous cell do ?***\n",
        "* ***Your** thoughts here*\n",
        "This code prepares the input placeholders for the neural network and computes the hidden representation of the word by linearly transforming the input x with the weight matrix W1 and the bias vector b1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fbO7czrSvBZC"
      },
      "outputs": [],
      "source": [
        "# Define the loss function:\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAK9auYVvBZC"
      },
      "source": [
        "### ***Which loss function is this ?***\n",
        "* ***Your** thoughts here*<br>\n",
        "The loss function is the cross-entropy loss, specifically the categorical cross-entropy loss.\n",
        "\n",
        "### ***Why do we use it here ?***\n",
        "* ***Your** thoughts here*<br>\n",
        "Cross entropy loss is commonly used in classification tasks because it measures the difference between the predicted probability distribution and the true distribution (uniquely thermally encoded labels). Cross-entropy loss has favourable properties for gradient-based optimisation: it imposes heavier penalties when the predicted probabilities differ significantly from the true values. This encourages the model to adjust its parameters to improve the prediction, which is important for training accurate word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DFLrQQfpvBZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the training step:\n",
        "# TODO 10: Use an optimizer to minimize the loss.\n",
        "# look through the documentation:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/GradientDescentOptimizer\n",
        "# tf.compat.v1 is replaced with tf in our code\n",
        "\n",
        "learning_rate = 0.01\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4lABxxyDvBZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_iters = 10000\n",
        "\n",
        "for _ in range(n_iters):\n",
        "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
        "\n",
        "vectors = sess.run(W1 + b1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGkw4BeyvBZD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBlg-A3UvBZD"
      },
      "source": [
        "### ***Reminder***\n",
        "\n",
        "Euclidian distance:\n",
        "$$ ||x-y||_2 = \\sqrt{ \\sum_{i=1}^{N} (x_i - y_i)^2 } $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xwa0Iw4-vBZD"
      },
      "outputs": [],
      "source": [
        "# TODO 11 (last one!): implement the euclidian distance function using numpy\n",
        "def euclidean_dist(vec1, vec2):\n",
        "    return np.sqrt(np.sum((vec1 - vec2) ** 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPWDBH5lvBZD"
      },
      "source": [
        "### ***What is TSNE ? How is it useful here ?***\n",
        "* ***Your** thoughts here*<br>\n",
        "The t-SNE can downscale high-dimensional data to a lower dimensional space. In natural language processing, word embeddings are usually high-dimensional, and t-SNE can downscale them to two or three dimensions for visualisation and analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IxdSFnNvBZD",
        "outputId": "dd0417f0-c26c-4696-95e6-1003630c649d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.8276927  -0.56118166]\n",
            " [-0.920084   -0.39172107]\n",
            " [-0.9541064   0.2994679 ]\n",
            " [ 0.807574   -0.5897664 ]\n",
            " [-0.99044746 -0.13789026]\n",
            " [-0.9973796   0.07234559]\n",
            " [-0.9654423  -0.26061684]\n",
            " [-0.99773425 -0.06727757]\n",
            " [-0.9966516   0.08176548]\n",
            " [-0.99238324 -0.12318914]\n",
            " [ 0.82616997 -0.56342095]\n",
            " [-0.90550464 -0.4243363 ]\n",
            " [-0.9890964  -0.1472699 ]\n",
            " [-0.97962356  0.20084254]\n",
            " [-0.9541648  -0.29928157]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "model = TSNE(n_components=2, perplexity=2, random_state=0)\n",
        "np.set_printoptions(suppress=True)\n",
        "vectors = model.fit_transform(vectors)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "normalizer = preprocessing.Normalizer()\n",
        "vectors =  normalizer.fit_transform(vectors, 'l2')\n",
        "\n",
        "print(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "f7s2Q6OSvBZE",
        "outputId": "ce9c4476-b345-4dd4-ff3a-204c018faed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'is', 'the', 'king', '.', 'the', 'king', 'is', 'royal', '.', 'she', 'is', 'the', 'royal', 'queen']\n",
            "he -0.56118166\n",
            "is -0.39172107\n",
            "the 0.2994679\n",
            "king -0.5897664\n",
            ". -0.13789026\n",
            "the 0.2994679\n",
            "king -0.5897664\n",
            "is -0.39172107\n",
            "royal 0.08176548\n",
            ". -0.13789026\n",
            "she -0.56342095\n",
            "is -0.39172107\n",
            "the 0.2994679\n",
            "royal 0.08176548\n",
            "queen -0.29928157\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "print(words)\n",
        "for word in words:\n",
        "    print(word, vectors[word2int[word]][1])\n",
        "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
        "    ax.set_xlim(min([vectors[word2int[w]][0] for w in words])-1, max([vectors[word2int[w]][0] for w in words])+1)\n",
        "    ax.set_ylim(min([vectors[word2int[w]][1] for w in words])-1, max([vectors[word2int[w]][1] for w in words])+1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDsbK9bOvBZE"
      },
      "source": [
        "### ***You should see something similar:***\n",
        "<img src=\"word_2_vec_result.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4vbqey5vBZE"
      },
      "source": [
        "### ***Comment on what you've understood from this course***\n",
        "For example:\n",
        "* What is word2vec ? <br>\n",
        "The goal of Word2Vec is to capture the semantic relationships between words by representing each word as a dense set of vectors of real numbers.\n",
        "* Why is it an improvement on BoW and TF-IDF <br>\n",
        "Word2Vec takes into account the context in which words appear, allowing subtle semantic relationships to be captured.BoW and TF-IDF treat all words as independent features.Word2Vec embeddings can be used to compute word similarity, which is not directly feasible in BoW or TF-IDF.\n",
        "* What is an encoder network, can you imagine an example to illustrate this notion ?<br>\n",
        "Let's consider an example of an image autoencoder:\n",
        "Input: a greyscale image (e.g., 28x28 pixels).\n",
        "Encoder network: the encoder network consists of a convolutional layer followed by a fully connected layer. It takes the image as input and learns to map it to low-dimensional vectors that are usually much smaller than the original image size (encoding).\n",
        "Decoder network: the decoder network accepts the encoding and reconstructs the original image from it. It contains layers for upsampling and convolution operations.\n",
        "Goal: During training, the goal of the autoencoder is to minimise the reconstruction error and ensure that the decoder output is as close as possible to the input image.<br>\n",
        "Encoder networks play a key role in compressing information from an input image into a compact representation, which is useful for tasks such as image denoising, dimensionality reduction or feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4p1cKq1_-bH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}